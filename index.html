<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Sensor Fusion Project</title>
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
   <div class="scanner"></div>
   <h1>TEAM TERMINATORS</h1>
   <h2>Bayesian Sensor Fusion | CSE 5694 Project 1</h2>
  </header>

  <div class="crosshair"></div>

  <main>
    
    <section class="card">
       <h3>Team Description</h3>
       <p>
          <b>Team Name:</b> Terminators<br>
          <b>Course:</b> CSE 5694 – Sensor Fusion and Robotics<br>
          <b>Members:</b><br>
          Prem Pochiraju <br>
          Vijay Teja Uppalapati<br>
          Sumana Boyapalli <br>
          Raghvendra Huliyurdurga Mallesha
       </p>
     </section>


    <!-- <section class="card">
      <h3>Project 1 Description</h3>
      <p>
        This project involves developing a sensor fusion module for a robot that uses a Bayesian Network to decide:
      </p>
      <ul>
        <li>Whether it has just passed a door</li>
        <li>Its actual distance from the wall as a probability distribution</li>
      </ul>
      <p>
        The robot uses its onboard sensors for continuous data collection while moving along a wall. The Bayesian Network processes
        this sensor data to make real-time decisions based on a set of Conditional Probability Tables (CPTs).
      </p>
    </section> -->

    <section class="card">
      <h3>Project 1 Overview</h3>
      <p>
       This project implements a <b>Bayesian Sensor Fusion system</b> for an iCreate3 robot to detect when it passes a door while wall-following. 
       The robot uses sonar, IR, and bump sensors to estimate its distance from the wall and determine if it has just passed a door.
      </p>
      <p>
       The fusion logic is implemented using a <b>Dynamic Bayesian Network (DBN)</b> that integrates multiple noisy sensor readings 
       into a probabilistic belief map representing the robot’s environment and state transitions.
      </p>
      <p>
       A <b>PID controller</b> ensures stable wall-following, maintaining a consistent distance from the wall while continuously collecting sensor data.
      </p>
    </section>


     <section class="card">
      <h3>Project 1 Overview</h3>
      <p>
       This project implements a <b>Bayesian Sensor Fusion system</b> for an iCreate3 robot to detect when it passes a door while wall-following. 
       The robot uses sonar, IR, and bump sensors to estimate its distance from the wall and determine if it has just passed a door.
      </p>
      <p>
       The fusion logic is implemented using a <b>Dynamic Bayesian Network (DBN)</b> that integrates multiple noisy sensor readings 
       into a probabilistic belief map representing the robot’s environment and state transitions.
      </p>
      <p>
       A <b>PID controller</b> ensures stable wall-following, maintaining a consistent distance from the wall while continuously collecting sensor data.
      </p>
    </section>


    <section class="card">
      <h3>iCreate3 Robot Description</h3>
      <img src="robot.png" alt="iCreate3 Robot" class="image" />
      <p>
        The iRobot Create3 is designed for research and educational purposes, providing a platform for exploring robotics concepts.
        It is compatible with ROS2 and can connect via Wi-Fi or Bluetooth.
      </p>
      <ul>
        <li>7x Infrared Sensor s</li>
        <li>4x Cliff Sensors</li>
        <li>2x Bumper Sensors</li>
        <li>Optical Wheel Encoders</li>
        <li>Charging Contacts & Docking Sensor</li>
      </ul>
    </section>

    <section class="card">
      <h3>Dynamic Bayesian Network Description</h3>
      <img src="bayesian_network_diagram.png" alt="Bayesian Network Diagram" class="image" />
  
      <p>
        The Sensor Fusion Network comprises key variables to interpret its sensor readings as a distance to the wall. 
        The Hidden Markov Model uses this interpreted sonar reading to determine whether or not a door was passed 
        by generating a belief of the robot's current state. The color of the power button indicates what the robot 
        believes its current state is. Once the color transitions from <b>"door passed"</b> to <b>"wall following"</b>, 
        the door counter is incremented by 1. The CPTs are learned from the data obtained during multiple tests where 
        all variables (observable and unobservable) are recorded and provide probabilistic estimates for each variable’s state.
      </p>

      <h4>Variables</h4>
      <ul>
        <li><b>RobotState:</b> Indicates which state the robot is in
          <ul>
           <li>Wall Following (<span style="color:green;">green</span>)</li>
           <li>Possible Door Frame (<span style="color:gold;">yellow</span>)</li>
           <li>In Door Frame (<span style="color:magenta;">magenta</span>)</li>
           <li>Passed Door Frame (<span style="color:blue;">blue</span>)</li>
           <li>Return Home (<span style="color:red;">red</span>)</li>
          </ul>
         </li>
         <li><b>Wall Distance [Close, Moderate, Far]:</b> Indicates approximate distance between the robot and the wall on its right.</li>
         <li><b>Bump [True, False]:</b> Indicates whether a bump or collision occurred.</li>
         <li><b>IR Sensor [Low, Medium, High]:</b> Indicates reflectometer reading from the right-hand side of the robot. 
             Lighter-colored objects will be registered better than darker ones.</li>
       </ul>
    </section>


    

    <section class="card">
     <h3>Source Code & Dependencies</h3>
     <p>
       View the project on GitHub:
       <a href="https://github.com/prempochiraju/Create3_BayesianFusion" target="_blank">
         https://github.com/prempochiraju/Create3_BayesianFusion
       </a>
     </p>
    </section>

  </main>

  <footer>
    <p>© CSE5694, 2025. Sensor Fusion Project for Bayesian Network-based Decision Making.</p>
  </footer>
</body>
</html>

